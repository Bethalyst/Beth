{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOEFfsL8mWRXTae5E+bkTdJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-tCQ33znf4p","executionInfo":{"status":"ok","timestamp":1764001133348,"user_tz":300,"elapsed":36218,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"efc787a7-dcc0-4d55-8b0a-e041f3fdada0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n","Collecting sumy\n","  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n","Collecting yake\n","  Downloading yake-0.6.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n","Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.20.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.10)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n","Collecting docopt<0.7,>=0.6.1 (from sumy)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting breadability>=0.1.20 (from sumy)\n","  Downloading breadability-0.1.20.tar.gz (32 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pycountry>=18.2.23 (from sumy)\n","  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n","Collecting jellyfish (from yake)\n","  Downloading jellyfish-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (642 bytes)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from yake) (3.5)\n","Collecting segtok (from yake)\n","  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from yake) (0.9.0)\n","Requirement already satisfied: chardet in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.2.0)\n","Requirement already satisfied: lxml>=2.0 in /usr/local/lib/python3.12/dist-packages (from breadability>=0.1.20->sumy) (5.4.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.11.12)\n","Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n","Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n","Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yake-0.6.0-py3-none-any.whl (80 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jellyfish-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m360.5/360.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: breadability, docopt\n","  Building wheel for breadability (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21695 sha256=b87dcfa38b5d8e58cc6d618d1573f38579f90f6f1c566beeecdd47ffd7a42674\n","  Stored in directory: /root/.cache/pip/wheels/32/99/64/59305409cacd03aa03e7bddf31a9db34b1fa7033bd41972662\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=9cef6fc98fd9f6e25c486fb6562b9cca94bd2384762f03f146fdb8a6f010baad\n","  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n","Successfully built breadability docopt\n","Installing collected packages: docopt, segtok, pycountry, jellyfish, breadability, yake, sumy\n","Successfully installed breadability-0.1.20 docopt-0.6.2 jellyfish-1.2.1 pycountry-24.6.1 segtok-1.5.11 sumy-0.11.0 yake-0.6.0\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["#!pip install -q openai-whisper gtts\n","!pip install textblob nltk spacy sumy yake\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","source":["# Import necessary libraries\n","#import whisper\n","#from gtts import gTTS\n","from textblob import TextBlob\n","import nltk\n","import spacy\n","from sumy.parsers.plaintext import PlaintextParser\n","from sumy.nlp.tokenizers import Tokenizer\n","from sumy.summarizers.lsa import LsaSummarizer\n","import yake\n","import IPython.display as ipd\n","import os"],"metadata":{"id":"lRSK2Tirn1yv","executionInfo":{"status":"ok","timestamp":1764001143930,"user_tz":300,"elapsed":10580,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Download NLTK resources\n","nltk.download(\"punkt\")\n","nltk.download(\"averaged_perceptron_tagger\")\n","nltk.download('punkt_tab')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ba6i-TLxokXT","executionInfo":{"status":"ok","timestamp":1764001154120,"user_tz":300,"elapsed":1373,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"63d8cd80-a587-4904-e670-d20404624928"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# --- TOKENIZATION (NLTK) ---\n","text = \"The quick brown fox jumps over the lazy dog.\"\n","tokens = nltk.word_tokenize(text)\n","print(\"Tokenized Words:\", tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_YIYpNXwo2Wq","executionInfo":{"status":"ok","timestamp":1764001220048,"user_tz":300,"elapsed":80,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"ba7371c4-2e3e-42b7-8817-324bb1b25088"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenized Words: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"]}]},{"cell_type":"code","source":["# --- SENTIMENT ANALYSIS (TextBlob) ---\n","blob = TextBlob(\"I've been wearing these for almost 30 years. I just bought 3 more pairs. They're durable and extremely comfortable. If they're not comfortable for you, maybe you have the wrong size, or maybe it's just not the shoe for you. A pair usually lasts me 2 years, but I wear them until they start to fall apart. To those people who say that the front part separates: you're probably washing them in the washing machine in warm or hot water; don't. If you must wash them, do it by hand, cold water, if possible. And you can repair them with glue if necessary, but it shouldn't be most of the time. I'm one of the 9 out of 10 that they work for.\")\n","print(\"Sentiment Polarity:\", blob.sentiment.polarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u_2e727zqTqz","executionInfo":{"status":"ok","timestamp":1764001790763,"user_tz":300,"elapsed":5,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"726ce200-098b-49c4-e39b-f4430a580cb7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentiment Polarity: 0.06363636363636363\n"]}]},{"cell_type":"code","source":["# --- NAMED ENTITY RECOGNITION (spaCy) ---\n","nlp = spacy.load(\"en_core_web_sm\")\n","doc = nlp(\"Ronald Reagan was the best president serving in the white house for the united states of america in washington d.c.\")\n","print(\"Named Entities:\")\n","for ent in doc.ents:\n","    print(f\"{ent.text} -> {ent.label_}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSLF87NQrSpj","executionInfo":{"status":"ok","timestamp":1764001856198,"user_tz":300,"elapsed":1113,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"f44bbc9d-dba4-4639-9272-fa8485177489"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Named Entities:\n","Ronald Reagan -> PERSON\n","the white house -> ORG\n","the united states of america -> GPE\n","washington -> GPE\n","d.c -> GPE\n"]}]},{"cell_type":"code","source":["# --- TEXT SUMMARIZATION (Sumy) ---\n","long_text = \"Natural Language Processing (NLP) is a field of AI that enables computers to understand, interpret, and generate human language. It is used in various applications like chatbots, speech recognition, and machine translation.\"\n","parser = PlaintextParser.from_string(long_text, Tokenizer(\"english\"))\n","summarizer = LsaSummarizer()\n","summary = summarizer(parser.document, 1)\n","print(\"Summary:\")\n","for sentence in summary:\n","    print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v_muLuWgsWtm","executionInfo":{"status":"ok","timestamp":1764002034234,"user_tz":300,"elapsed":358,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"65afa79a-7410-4c51-f2fe-a85ab531b5e4"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary:\n","It is used in various applications like chatbots, speech recognition, and machine translation.\n"]}]},{"cell_type":"code","source":["with open(\"AI.txt\", 'r') as file:\n","        long_text = file.read()\n","\n","parser = PlaintextParser.from_string(long_text, Tokenizer(\"english\"))\n","summarizer = LsaSummarizer()\n","summary = summarizer(parser.document, 2)\n","\n","print(\"Summary:\")\n","for sentence in summary:\n","    print(sentence)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y3RyT_78hieT","executionInfo":{"status":"ok","timestamp":1764002380170,"user_tz":300,"elapsed":30,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"e0a5311e-6848-40fd-fb5f-e2fd97ccfded"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Summary:\n","Enhanced Social Engineering: Generative AI enables the creation of highly convincing phishing emails, deepfake audio of executives, and other scams that are difficult to detect and leverage fluent language or cloned voices.\n","Sensitive Data Leakage: Organizations face the risk of sensitive data being leaked when employees input confidential information into public AI systems for analysis or other tasks.\n"]}]},{"cell_type":"code","source":["# --- KEYWORD EXTRACTION (YAKE!) ---\n","kw_extractor = yake.KeywordExtractor()\n","keywords = kw_extractor.extract_keywords(long_text)\n","print(\"Keywords:\")\n","for kw, score in keywords:\n","    print(f\"{kw}: {score}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X5Jr-o4Fs_3P","executionInfo":{"status":"ok","timestamp":1744647475816,"user_tz":240,"elapsed":229,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"7ee263b7-3ef5-47eb-8580-2d954efccb58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Keywords:\n","Opportunities Artificial Intelligence: 0.0003338951169874817\n","Artificial Intelligence: 0.004659266349208434\n","Opportunities Artificial: 0.005068413083073986\n","revolutionizing various industries: 0.0392624775229878\n","Cybersecurity: 0.06289322198253715\n","Intelligence: 0.0653071233079033\n","Opportunities: 0.07101305384795686\n","Artificial: 0.07101305384795686\n","Risks and Opportunities: 0.080853833157882\n","Risks: 0.08316193575886564\n","including cybersecurity: 0.08807487316013625\n","threat detection: 0.10079364800061356\n","Ethical Considerations: 0.12236253781770326\n","potential: 0.12916153196083002\n","detection: 0.13307033700433585\n","vulnerabilities: 0.13512077945169426\n","potential risks: 0.1368018977034984\n","cyber threats: 0.15097203705744122\n","Ethical: 0.158960668782463\n","Automated Responses: 0.16032320253160537\n"]}]},{"cell_type":"code","source":["from transformers import pipeline\n","\n","generator = pipeline('text-generation', model='gpt2')\n","result = generator(\"My professor told me this course was easy. Then I found out.\",\n","                   max_length=150,\n","                   truncation=True,\n","                   eos_token_id=50256,  # GPT-2's end-of-sequence token\n","                   pad_token_id=50256,  # Ensure padding uses the same token\n","                   num_return_sequences=1\n","                   )\n","print(result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tNikqj--uKxh","executionInfo":{"status":"ok","timestamp":1764002756538,"user_tz":300,"elapsed":13293,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"3f316d83-c0b6-44af-9d95-59c690dbffe1"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n","Both `max_new_tokens` (=256) and `max_length`(=150) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"]},{"output_type":"stream","name":"stdout","text":["[{'generated_text': \"My professor told me this course was easy. Then I found out.\\n\\nIn the fall of 2012, I went to grad school in Washington, D.C., and got my bachelor's degree at NYU. A year later, I got my Ph.D. from Columbia University.\\n\\nA few years later, I got a job at a tech company in San Francisco, where I worked on a startup called Smart City. It was a big deal. I was a startup founder, and my boss was a computer scientist.\\n\\nI started working for the company.\\n\\nThe idea was, we could build a smart city. We wanted to make it better. It was like a self-driving car. We had a great idea. We built a city. We were building it.\\n\\nI came up with the idea of building a smart city, and I worked in a tech company for almost a year. I was starting out as a PhD candidate at NYU, but then I got a job working at IBM.\\n\\nI came up with the idea that we could build a smart city and I'm a computer scientist. I was working at IBM as a professor of computer science. I did some pretty good research, and I was able to come up with the concept of smart city.\\n\\nI had a dream.\"}]\n"]}]},{"cell_type":"code","source":["print(result[0]['generated_text'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wF16_uOlvSkJ","executionInfo":{"status":"ok","timestamp":1764002761642,"user_tz":300,"elapsed":14,"user":{"displayName":"Kris Roberts","userId":"16396374602623502602"}},"outputId":"0fa7b065-20a0-485a-d075-36f9f1169056"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["My professor told me this course was easy. Then I found out.\n","\n","In the fall of 2012, I went to grad school in Washington, D.C., and got my bachelor's degree at NYU. A year later, I got my Ph.D. from Columbia University.\n","\n","A few years later, I got a job at a tech company in San Francisco, where I worked on a startup called Smart City. It was a big deal. I was a startup founder, and my boss was a computer scientist.\n","\n","I started working for the company.\n","\n","The idea was, we could build a smart city. We wanted to make it better. It was like a self-driving car. We had a great idea. We built a city. We were building it.\n","\n","I came up with the idea of building a smart city, and I worked in a tech company for almost a year. I was starting out as a PhD candidate at NYU, but then I got a job working at IBM.\n","\n","I came up with the idea that we could build a smart city and I'm a computer scientist. I was working at IBM as a professor of computer science. I did some pretty good research, and I was able to come up with the concept of smart city.\n","\n","I had a dream.\n"]}]}]}