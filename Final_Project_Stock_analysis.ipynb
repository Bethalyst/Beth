{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c1d119a",
   "metadata": {},
   "source": [
    "# Final Project: S&P 500 (SPY) Buy/Sell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3abc1e9",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "My original plan was to treat the Tesla Stock as a **regression** problem by using **Linear Regression** to predict future prices directly. After some research and suggestion i learned very quickly that predicting the stock market is more difficult than i assumed. I adjusted my approach to a simple buy/sell indicator model: instead of forecasting an exact future price, I reframed the problem as **binary classification** (1 = price is higher after 10 trading days, 0 = not higher). I built basic “chart‑style” features from OHLCV (Open, High, Low, Close, and Volume) data with additional feature analysis(returns, log returns, rolling averages, and simple moving‑average comparisons) and trained a **Perceptron** model. Performance is than evaluated using **accuracy** and **K‑Fold cross‑validation** on the training set to estimate how stable the accuracy is across different splits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1edf7f",
   "metadata": {},
   "source": [
    "- Imported pandas for working with tables (DataFrames) to clean, columns selection, and saving CSV files.\n",
    "- Imported  numpy for math operations (log, arrays) ect.\n",
    "- Imported matplotlib for charts and basic ploting (we will plot the confusion matrix)\n",
    "- Imported yfinance to download market data from Yahoo Finance.\n",
    "- Imported KFold for K-Fold cross-validation. It split training data into folds\n",
    "- Imported cross_val_score to measure cross-validation accuracy.\n",
    "- Imported StandardScaler to scale features (helps Perceptron training)\n",
    "- Imported Perceptron for a simple linear classification model.\n",
    "- Imported Pipeline to combine scaling + model in one object.\n",
    "- Imported accuracy_score to compute accuracy\n",
    "- Imported confusion_matrix to build the 2x2 confusion matrix.\n",
    "- Imported classification_report for readable metrics summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8409062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import yfinance as yf \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import classification_report \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "92876508",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-02</th>\n",
       "      <td>171.093689</td>\n",
       "      <td>172.301341</td>\n",
       "      <td>170.052618</td>\n",
       "      <td>171.884913</td>\n",
       "      <td>121465900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05</th>\n",
       "      <td>168.003754</td>\n",
       "      <td>170.210818</td>\n",
       "      <td>167.695601</td>\n",
       "      <td>170.044249</td>\n",
       "      <td>169632600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-06</th>\n",
       "      <td>166.421387</td>\n",
       "      <td>168.836665</td>\n",
       "      <td>165.621839</td>\n",
       "      <td>168.311962</td>\n",
       "      <td>209151400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-07</th>\n",
       "      <td>168.495163</td>\n",
       "      <td>168.836637</td>\n",
       "      <td>167.304185</td>\n",
       "      <td>167.753921</td>\n",
       "      <td>125346700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-08</th>\n",
       "      <td>171.485153</td>\n",
       "      <td>171.701704</td>\n",
       "      <td>169.894407</td>\n",
       "      <td>169.911055</td>\n",
       "      <td>147217800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price            Close        High         Low        Open     Volume\n",
       "Date                                                                 \n",
       "2015-01-02  171.093689  172.301341  170.052618  171.884913  121465900\n",
       "2015-01-05  168.003754  170.210818  167.695601  170.044249  169632600\n",
       "2015-01-06  166.421387  168.836665  165.621839  168.311962  209151400\n",
       "2015-01-07  168.495163  168.836637  167.304185  167.753921  125346700\n",
       "2015-01-08  171.485153  171.701704  169.894407  169.911055  147217800"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the ticker symbol for the S&P 500 ETF (SPY).\n",
    "ticker = \"SPY\"  \n",
    "# Choose a start date to have enough history for rolling features.\n",
    "start_date = \"2015-01-01\"  \n",
    "# Download the data from Yahoo Finance.\n",
    "df_raw = yf.download(ticker, start=start_date, auto_adjust=True)  # auto_adjust=True uses adjusted prices.\n",
    "\n",
    "if isinstance(df_raw.columns, pd.MultiIndex):  # check whether columns have multiple levels.\n",
    "    df_raw.columns = df_raw.columns.get_level_values(0)  # keep only the first level (OHLCV names).\n",
    "\n",
    "df_raw.head()  # show the top rows in the table.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2451fbc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>return</th>\n",
       "      <th>log_ret</th>\n",
       "      <th>df_l</th>\n",
       "      <th>df_hmi</th>\n",
       "      <th>close_vs_sma10</th>\n",
       "      <th>close_vs_sma20</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-30</th>\n",
       "      <td>197729700</td>\n",
       "      <td>167.0460</td>\n",
       "      <td>168.3785</td>\n",
       "      <td>165.8467</td>\n",
       "      <td>166.1132</td>\n",
       "      <td>-0.0126</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>167.4133</td>\n",
       "      <td>169.8194</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>-0.0155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-02</th>\n",
       "      <td>163107000</td>\n",
       "      <td>166.6129</td>\n",
       "      <td>168.2620</td>\n",
       "      <td>164.7890</td>\n",
       "      <td>168.1704</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>167.3558</td>\n",
       "      <td>169.8369</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>-0.0024</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03</th>\n",
       "      <td>124212900</td>\n",
       "      <td>169.0699</td>\n",
       "      <td>170.6107</td>\n",
       "      <td>168.6951</td>\n",
       "      <td>170.6023</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>167.5541</td>\n",
       "      <td>170.0143</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04</th>\n",
       "      <td>134306700</td>\n",
       "      <td>169.8361</td>\n",
       "      <td>171.0521</td>\n",
       "      <td>169.4947</td>\n",
       "      <td>169.9527</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>167.7681</td>\n",
       "      <td>170.1576</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-05</th>\n",
       "      <td>97953200</td>\n",
       "      <td>170.6189</td>\n",
       "      <td>171.8183</td>\n",
       "      <td>170.5440</td>\n",
       "      <td>171.6683</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>167.9713</td>\n",
       "      <td>170.1609</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price          Volume      Open      High       Low     Close  return  \\\n",
       "Date                                                                    \n",
       "2015-01-30  197729700  167.0460  168.3785  165.8467  166.1132 -0.0126   \n",
       "2015-02-02  163107000  166.6129  168.2620  164.7890  168.1704  0.0124   \n",
       "2015-02-03  124212900  169.0699  170.6107  168.6951  170.6023  0.0145   \n",
       "2015-02-04  134306700  169.8361  171.0521  169.4947  169.9527 -0.0038   \n",
       "2015-02-05   97953200  170.6189  171.8183  170.5440  171.6683  0.0101   \n",
       "\n",
       "Price       log_ret      df_l    df_hmi  close_vs_sma10  close_vs_sma20  \\\n",
       "Date                                                                      \n",
       "2015-01-30  -0.0127  167.4133  169.8194         -0.0163         -0.0155   \n",
       "2015-02-02   0.0123  167.3558  169.8369         -0.0043         -0.0024   \n",
       "2015-02-03   0.0144  167.5541  170.0143          0.0087          0.0112   \n",
       "2015-02-04  -0.0038  167.7681  170.1576          0.0044          0.0063   \n",
       "2015-02-05   0.0100  167.9713  170.1609          0.0145          0.0155   \n",
       "\n",
       "Price       Target  \n",
       "Date                \n",
       "2015-01-30       1  \n",
       "2015-02-02       1  \n",
       "2015-02-03       1  \n",
       "2015-02-04       1  \n",
       "2015-02-05       1  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a copy so we do not accidentally overwrite the raw data.\n",
    "df = df_raw.copy()  \n",
    "\n",
    "# Pick the price column to use as the main “close” price.\n",
    "price_col = \"Close\"  \n",
    "\n",
    "# Create new return column to calculate percentage change from previous close.\n",
    "df[\"return\"] = df[price_col].pct_change() \n",
    "\n",
    "# Create log return dispaly difference of log prices.\n",
    "df[\"log_ret\"] = np.log(df[price_col]).diff()  \n",
    "\n",
    "# Create 10-day rolling mean of Low \n",
    "df[\"df_l\"] = df[\"Low\"].rolling(window=10).mean()  # average Low over last 10 trading days.\n",
    "\n",
    "# Create 10-day rolling mean of High \n",
    "df[\"df_hmi\"] = df[\"High\"].rolling(window=10).mean()  # average High over last 10 trading days.\n",
    "\n",
    "# Create a 10-day simple moving average of Close.\n",
    "df[\"sma10\"] = df[price_col].rolling(window=10).mean()  # average Close over 10 days.\n",
    "\n",
    "# Create a 20-day simple moving average of Close.\n",
    "df[\"sma20\"] = df[price_col].rolling(window=20).mean()  # average Close over 20 days.\n",
    "\n",
    "# Compare Close to SMA10 \n",
    "df[\"close_vs_sma10\"] = (df[price_col] / df[\"sma10\"]) - 1  # positive means above SMA10, negative means below.\n",
    "\n",
    "# Compare Close to SMA20 .\n",
    "df[\"close_vs_sma20\"] = (df[price_col] / df[\"sma20\"]) - 1  # another trend indicator.\n",
    "\n",
    "horizon = 10  # how far ahead we look to label buy/sell for 10 trading days ~ 2 weeks\n",
    "\n",
    "# Target column (1 if future Close is higher than today, else 0).\n",
    "df[\"Target\"] = (df[price_col].shift(-horizon) > df[price_col]).astype(int) \n",
    "\n",
    "# Selected columns we need for modeling (inputs + target).\n",
    "df_model = df[[\"Volume\", \"Open\", \"High\", \"Low\", \"Close\", \"return\", \"log_ret\",\n",
    "                \"df_l\", \"df_hmi\", \"close_vs_sma10\", \"close_vs_sma20\", \"Target\"]].copy() \n",
    "\n",
    "# Drop rows with missing values (NaNs)\n",
    "df_model = df_model.dropna()  # scikit-learn keeps giving errors.\n",
    "\n",
    "df_model = df_model.round(4)  # limit decimals to keep tables readable.\n",
    "\n",
    "# Show the dataset preview.\n",
    "df_model.head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2a5a8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleansed dataset to: clean_spy_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleansed dataset to a CSV file.\n",
    "clean_csv_path = \"clean_spy_dataset.csv\" \n",
    "df_model.to_csv(clean_csv_path, index=True)  # write the CSV to disk with the date index.\n",
    "\n",
    "# Print the filename so you know what was created.\n",
    "print(\"Saved cleansed dataset to:\", clean_csv_path)  # also show where the file is saved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0dc2ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 2190 Test rows: 548\n"
     ]
    }
   ],
   "source": [
    "# Create a list of feature to inputs into the model\n",
    "feature_cols = [  \n",
    "    \"Volume\",\n",
    "    \"Open\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Close\",\n",
    "    \"return\",  #daily return.\n",
    "    \"log_ret\",  #daily log return.\n",
    "    \"df_l\",  #10-day average Low.\n",
    "    \"df_hmi\",  #10-day average High.\n",
    "    \"close_vs_sma10\",  #Close compared to SMA10.\n",
    "    \"close_vs_sma20\",  #Close compared to SMA20.\n",
    "]\n",
    "\n",
    "# X (features) and y (target).\n",
    "X = df_model[feature_cols].copy()\n",
    "y = df_model[\"Target\"].copy()\n",
    "\n",
    "# Split the data into train and test sets \n",
    "train_fraction = 0.80  # 80% train, 20% test.\n",
    "train_size = int(len(df_model) * train_fraction)  \n",
    "\n",
    "# Use the first 80% of rows for training \n",
    "X_train = X.iloc[:train_size].copy()  \n",
    "y_train = y.iloc[:train_size].copy()  \n",
    "\n",
    "# Use the last 20% of rows for testing \n",
    "X_test = X.iloc[train_size:].copy()  \n",
    "y_test = y.iloc[train_size:].copy()  \n",
    "\n",
    "# Print sizes to verify the split.\n",
    "print(\"Train rows:\", len(X_train), \"Test rows:\", len(X_test))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86946a4",
   "metadata": {},
   "source": [
    "Build a simple pipeline: scale features, then fit a perceptron classifier. Pipeline ensures we scale and predict consistently\n",
    "K-Fold Splitter a model evaluation technique that involves splitting the dataset into 'k' equal-sized subsets, or folds, to provide a reliable estimate of a model's performance to prevent overfitting that can occur with a single train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c1058ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold accuracies: [0.532 0.674 0.662 0.333 0.484]\n",
      "K-Fold mean accuracy: 0.537\n",
      "K-Fold std deviation: 0.125\n",
      "Test accuracy: 0.445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.332     0.751     0.461       173\n",
      "           1      0.726     0.304     0.429       375\n",
      "\n",
      "    accuracy                          0.445       548\n",
      "   macro avg      0.529     0.528     0.445       548\n",
      "weighted avg      0.602     0.445     0.439       548\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Pipeline([ \n",
    "    (\"scaler\", StandardScaler()),  # scale each feature to mean=0, std=1.\n",
    "    (\"clf\", Perceptron(random_state=42, max_iter=2000, tol=1e-4)),  # linear decision model.\n",
    "]) \n",
    "\n",
    "k = 5  # number of folds.\n",
    "kf = KFold(n_splits=k, shuffle=False)  # shuffle=False keeps the rows in order since it time-series data.\n",
    "\n",
    "# Run cross-validation on the trainnig data\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring=\"accuracy\")\n",
    "\n",
    "# Print cross-validation results.\n",
    "print(\"K-Fold accuracies:\", np.round(cv_scores, 3))  # show each fold's accuracy.\n",
    "print(\"K-Fold mean accuracy:\", round(float(cv_scores.mean()), 3))  # average accuracy.\n",
    "print(\"K-Fold std deviation:\", round(float(cv_scores.std()), 3))  # how much results vary.\n",
    "\n",
    "# Fit the model \n",
    "model.fit(X_train, y_train) \n",
    "\n",
    "test_pred = model.predict(X_test)  # predicted 0/1 labels for test rows.\n",
    "\n",
    "# Compute test accuracy.\n",
    "test_acc = accuracy_score(y_test, test_pred)  \n",
    "\n",
    "print(\"Test accuracy:\", round(float(test_acc), 3))  # main metric (accuracy).\n",
    "print(classification_report(y_test, test_pred, digits=3))  # precision/recall/F1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "79379e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix (10 test records):\n",
      "[[1 4]\n",
      " [3 2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved supplemental file: confusion_matrix_10_records.png\n",
      "Saved supplemental file: perceptron_coefficients.csv\n",
      "Saved supplemental file: test_set_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "# Select 10 records from the test set and creat a copy\n",
    "X_test_10 = X_test.iloc[:10].copy()  \n",
    "y_test_10 = y_test.iloc[:10].copy()  \n",
    "\n",
    "# Run the perceptron on these 10 records.\n",
    "pred_10 = model.predict(X_test_10)  \n",
    "\n",
    "# Build a 2x2 confusion matrix.\n",
    "cm_10 = confusion_matrix(y_test_10, pred_10, labels=[0, 1])  # rows=true, cols=pred.\n",
    "\n",
    "# Print the confusion matrix numbers.\n",
    "print(\"Confusion matrix (10 test records):\")  \n",
    "print(cm_10)  # show counts.\n",
    "\n",
    "# Plot the confusion matrix \n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(cm_10)\n",
    "plt.title(\"Confusion Matrix (10 Test Records)\")\n",
    "plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n",
    "plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n",
    "for i in range(2):\n",
    "    for j in range(2): \n",
    "        plt.text(j, i, str(cm_10[i, j]), ha=\"center\", va=\"center\")  # print count in each cell.\n",
    "plt.tight_layout()  # reduce extra whitespace.\n",
    "plt.show()\n",
    "\n",
    "# Save the confusion matrix figure as a file.\n",
    "cm_png_path = \"confusion_matrix_10_records.png\"\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(cm_10)  \n",
    "plt.title(\"Confusion Matrix (10 Test Records)\")  \n",
    "plt.xticks([0, 1], [\"Pred 0\", \"Pred 1\"])\n",
    "plt.yticks([0, 1], [\"True 0\", \"True 1\"])\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        plt.text(j, i, str(cm_10[i, j]), ha=\"center\", va=\"center\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(cm_png_path, dpi=150)\n",
    "plt.close()  # close the figure\n",
    "\n",
    "# Save the model coefficients as a CSV (decision model).\n",
    "clf = model.named_steps[\"clf\"]  # call out the perceptron inside the pipeline.\n",
    "coef = clf.coef_.ravel()  # perceptron weights\n",
    "coef_df = pd.DataFrame({\"feature\": feature_cols, \"weight\": coef})  # pair feature names with weights.\n",
    "coef_csv_path = \"perceptron_coefficients.csv\"  # filename\n",
    "coef_df.to_csv(coef_csv_path, index=False)  # save to CSV.\n",
    "\n",
    "# Also save test predictions as a file (optional but useful).\n",
    "pred_df = X_test.copy()  \n",
    "pred_df[\"y_true\"] = y_test.values \n",
    "pred_df[\"y_pred\"] = test_pred\n",
    "pred_csv_path = \"test_set_predictions.csv\" \n",
    "pred_df.to_csv(pred_csv_path, index=True)  # save to CSV.\n",
    "\n",
    "print(\"Saved supplemental file:\", cm_png_path)  # confusion matrix image.\n",
    "print(\"Saved supplemental file:\", coef_csv_path)  # perceptron weights.\n",
    "print(\"Saved supplemental file:\", pred_csv_path)  # test predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5353419b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest 10-day signal: SELL/ HOLD\n"
     ]
    }
   ],
   "source": [
    "# Get the most recent row in features\n",
    "latest_X = X.iloc[[-1]].copy() \n",
    "\n",
    "# Predict the latest 10-day direction signal.\n",
    "latest_signal = int(model.predict(latest_X)[0])  # 1 means predicted up, 0 means predicted not up.\n",
    "\n",
    "\n",
    "print(\"Latest 10-day signal:\", \"BUY\" if latest_signal == 1 else \"SELL/ HOLD\")  # interpret 1/0.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304e165c",
   "metadata": {},
   "source": [
    "### *Summary Report (Findings, Data Anomalies Ect..)*\n",
    "\n",
    "In this final project i builds a data‑driven model that mimics a basic version of real‑world chart analysis for the S&P 500 using the *SPY ETF* as the data source. Instead of predicting the exact future price (regression) as previously planned, i predicts a *directional signal* of the stock using binary classification:\n",
    "- **Target = 1 (BUY)** if the *Close price 10 trading days in the future* is higher than today’s Close  \n",
    "- **Target = 0 (SELL/HOLD)** otherwise\n",
    "This framing produces a clear decision output that matches “buy vs. sell” for long term stock trading.\n",
    "\n",
    "### Data source and cleansing steps\n",
    "Daily historical OHLCV data (Open, High, Low, Close, Volume) is downloaded with `yfinance` using `auto_adjust=True`, which adjusts prices for splits/dividends. Than features are then created:\n",
    "- `return` (percent change) and `log_ret` (log return)\n",
    "- 10‑day rolling averages of Low and High (`df_l`, `df_hmi`)\n",
    "- 10‑day and 20‑day moving averages (`sma10`, `sma20`)\n",
    "- Close‑to‑SMA comparisons (`close_vs_sma10`, `close_vs_sma20`)\n",
    "\n",
    "**Cleansing:** rolling averages and return calculations had produce missing values at the start of the dataset (for example, you cannot compute a 20‑day SMA until you have 20 rows). These missing rows are removed using `dropna()` so the final modeling dataset contains **no NaN values**. The cleansed dataset is saved as `clean_spy_dataset.csv`.\n",
    "\n",
    "### Modeling approach\n",
    "The final decision model is a **Perceptron** classifier wrapped in a pipeline:\n",
    "1) `StandardScaler` standardizes each feature  \n",
    "2) `Perceptron` learns a linear boundary to separate Target=1 from Target=0\n",
    "\n",
    "The perceptron produces a decision based on the sign of a weighted sum\n",
    "The learned weights are saved to `perceptron_coefficients.csv`.\n",
    "\n",
    "### Evaluation and required confusion matrix\n",
    "We evaluates the model in two ways as suggest in recent class lecture:\n",
    "- **K‑Fold cross‑validation (K=5)** on the training set to estimate stability of accuracy across splits  \n",
    "- **Hold‑out test set accuracy** using the most recent ~20% of rows as “future” data\n",
    "And to satisfy project requirement, exactly **10 records from the test set** are run through the perceptron and a **2×2 confusion matrix** is generated and plotted. That plot is saved as `confusion_matrix_10_records.png`.\n",
    "\n",
    "###  Key findings \n",
    "- The perceptron provides a *simple, explainable baseline* for direction prediction over a 10‑day horizon.\n",
    "- The K‑Fold accuracy values show how consistent performance is across different training/validation splits.\n",
    "- The test accuracy gives a realistic check using the newest portion of the data.\n",
    "- The latest predicted output is printed as a plain‑English signal (**BUY** or **SELL/HOLD**).\n",
    "\n",
    "### Data anomalies observed \n",
    "- **Missing values from feature engineering:** rolling windows and return calculations create NaNs at the start of the dataset. It must be handled ( by dropping rows or filling values) or the model will error.\n",
    "- **Outliers and volatility clusters:** SPY price changes can be unusually large during crisis periods. \n",
    "- **Volume spikes:** volume can jump significantly during major market events. Volume is informative but may also reflect rare events that do not repeat often.\n",
    "- **Market closures / uneven spacing:** the dataset contains trading days only (no weekends/holidays).\n",
    "\n",
    "### Questions to ask about the data \n",
    "Should the horizon stay at **10 trading days**, or should it be tested at 5 / 20 to see sensitivity?\n",
    "\n",
    "\n",
    "Supplemental files created\n",
    "\n",
    "- `clean_spy_dataset.csv` (cleansed dataset used for modeling)\n",
    "- `perceptron_coefficients.csv` (weights of the decision model)\n",
    "- `test_set_predictions.csv` (test predictions and true labels)\n",
    "- `confusion_matrix_10_records.png` (confusion matrix for 10 test records)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
